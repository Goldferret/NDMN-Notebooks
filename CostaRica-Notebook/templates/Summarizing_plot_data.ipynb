{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import geopandas as gpd, pandas as pd, os, numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Reading in the data and exploring using pandas and geopandas\n",
    "## Read the Costa_Classification_Data_Cleaned2.csv file into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../Costa_Rica_Data/Costa_Classification_Data_Cleaned2.csv') ##../ in the relative path moves out of the templates directory into the CostaRica-Notebook directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get basic information from the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape) #number of rows and columns\n",
    "display(df.columns) #all column names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split out response and predictor columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "id=['plotid', 'sampleid']\n",
    "\n",
    "resp=['Use', 'Cover', 'Vegetation', 'Herbaceous',\n",
    "       'Grass', 'Cultivation', 'WetLand', 'Terrain', 'Water', 'Another Class',\n",
    "       'SAF']\n",
    "pred=['BLUE', 'GREEN', 'NIR',\n",
    "       'RED', 'SWIR1', 'SWIR2', 'altura2', 'aspect', 'aspectcos', 'aspectdeg',\n",
    "       'aspectYesn', 'brightness', 'clay_1mMed', 'diff', 'elevation', 'evi',\n",
    "       'fpar', 'hand30_100', 'lai', 'mTPI', 'ndvi', 'ocs_1mMed', 'sand_1mMed',\n",
    "       'savi', 'Yeslt_1mMed', 'slope', 'topDiv', 'wetness']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at summary stats for predictor columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df[pred].describe()) #summary statistics for predictors\n",
    "display(df[pred].isna().sum()) #number of NAs by column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Explaining NAs\n",
    "- Why does altura2 have so many NAs (hint look at altura2 data in geemap? Can a different value be substituted for the NAs? \n",
    "- Why does savi, wetness, diff, and brightness have 26 NAs?\n",
    "- Why does topDiv have NAs?\n",
    "- Why does NDVI have NAs?\n",
    "- Why does mTPI have NAs?\n",
    "- What would happen if we did not address the NAs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addressing NA in predictors\n",
    "Here we will make 2 assumptions\n",
    "- altura2 nas should be changed to zero\n",
    "- all other na will be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['altura2'].isna(),'altura2']=0 #set na to zero\n",
    "df['altura2']\n",
    "df2=df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at summary stats for response columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df2[resp].describe()) #summary stats for response\n",
    "display((df2[resp].isna()).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Unique Categories\n",
    "- What are the unique categories for each response column and their frequency of occurrence?\n",
    "- How is Not_Applicable different from No Information?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at summary stats for plot id columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df2[id].describe()) #summary stats for response\n",
    "display((df2[id].isna()).sum())\n",
    "df_gr=df2[id].groupby('plotid')\n",
    "cnt_sampleid=df_gr.agg('size')\n",
    "display(np.unique(cnt_sampleid)) #display how many sampleid records are in each plotid\n",
    "display(cnt_sampleid[cnt_sampleid > 9]) #display which plots have more than 9 records\n",
    "display(df.loc[df['plotid']==1630]) #select just plot 1630 which sampleid to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Unique identifiers\n",
    "- Which column represents the plot and the subplot?\n",
    "- How many subplots are there per plot?\n",
    "- Why are there some subplots with 18 records?\n",
    "- Which plots have 18 records?\n",
    "- What should we do with those records?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing the duplicated sampleids\n",
    "#### There are many ways to address the duplicated (QAQC) plots. In this example we are going to just use the first sample collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df2.groupby(['plotid','sampleid']).first()#make sure to group on both plotid and sampleid to get all unique combinations\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Addressing duplicate samples\n",
    "- How many subplots were removed?\n",
    "- Does the total number of records make sense?\n",
    "- Select for the last value. Do you get the same number of records?\n",
    "- Can you think of another way to remove duplicated records?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating to the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "UseResp=pd.crosstab(df['plotid'],df['Use'],normalize='index')#percentage by use class\n",
    "pred_agg=df[['plotid']+pred].groupby('plotid').agg(['mean','std'])\n",
    "pred_agg.columns = [\"_\".join(a) for a in pred_agg.columns.to_flat_index()] #change the multilevel index to a single level index to merger DataFrames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the percent use columns with the mean and standard deviation of aggregated subplots to create a cleaned data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df=UseResp.merge(pred_agg,left_on='plotid',right_on='plotid')\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Summarizing plots\n",
    "- For each response variable create a clean percent category data frame with summarized mean, standard deviation, min, and max values. How many predictor variables do you have? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save out the plot and plot_subplot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath1 = 'plot_data.csv'\n",
    "outpath2= 'plot_subplot_data.csv'\n",
    "if(not os.path.exists(outpath1)):clean_df.to_csv(outpath1)\n",
    "if(not os.path.exists(outpath2)):df2.to_csv(outpath2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rstools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
